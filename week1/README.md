### Неделя 1
* [Материалы](https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie/home/week/1)

#### Лекционные заметки
1. Задача машинного обучения: Есть множество $n$ объёктов, которые описываются $m$ признаками (признаки бывают количественными, номинальными, ...), для каждого объекта обучающей выборки есть ответ и зная эти ответы нужно выбрать *модель* и минимизировать по пространству параметров модели (максимизировать, в зависимости от определения) функционал качества. *Модель* — это параметрическое *семейство алгоритмов*, каждый из которых действует из множества объектов в множество ответов. *Функционал качества* часто представляет из себя сумму по всем объектам *функции потерь*. Функция потерь — это функция, по объекту выдающая величину ошибки алгоритма (алгоритм принадлежит модели) на этом объекте.
2. Переобучение — частая проблема машинного обучения, которая заключается в том, что полученный алгоритм очень здорово работает на том, на чём его учили, но совсем нехорошо работает на новых данных. Пример: если в модель линейной регрессии добавлять в качестве факторов степени какого-нибудь одного признака вплость до $n$, то при больших $n$ будет получаться такая решающая функция, которая между точками обучающей выборки скачет как шальная.
3. Деревья решений — это метод классификации (и регрессии!). Говорят, что можно использовать на данных с пропусками (вводя вероятности на узлах дерева). Не то что бы в лекции они были супер классно раскрыты. Для меня вопрос построения множества предикатов (которые располагаются на узлах дерева) остаётся открытым. **Суть:** дерево строится исходно по всему множеству обучающих объектов и на каждом шаге мы разбиваем это множетсво на 2 части по предикату $\beta$. Этот предикат должен обладать максимальной информативностью в некотором смысле (хорошо отелять один класс, от другого или группу классов от другой группы классов). Про функционал, определяющий информативность предиката, почитай где-нибудь на wiki, если надо...

#### Подсказки
1. Масштабирование данных (нормализация) — это важно

